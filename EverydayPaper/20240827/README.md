# Show-o: One Single Transformer to Unify Multimodal Understanding and Generation

> This markdown file created on 20240827.

## Abstract

We present a unified transformer, Show-o. Show-o unifies autoregressive and (discrete) diffusion modeling to adaptively handle inputs and outputs of various and mixed modalities.



## Conclusion

This(unify AR and DDM) highlighted its potential as a next-generation foundation model.


## Architecture

- We design a unified prompting strategy to format various kinds of input data.
- We propose an omni-attention mechanism to enable Show-o to model various types of signals in distinct ways.
- We employ two learning objectives: 
  - Next Token Prediction (NTP)
  - Mask Token Prediction (MTP)
