# LONGVILA: SCALING LONG-CONTEXT VISUAL LANGUAGE MODELS FOR LONG VIDEOS

> This markdown file created on 20240828.

## Abstract

We introduce LongVILA, a full-stack solution for long-context visual-language models by co-designing the algorithm and system.

For model training, we upgrade existing VLMs to support long video understanding by:

- long context extension
- long supervised fine-tuning



## Introduction

For training system, we establish an efficient and user-friendly framework, namely Multi-Modal Sequence Parallelism (MM-SP), which supports training memoryintensive long-context VLMs. 



## Words

- circumvent 逃避，规避
- sidestep 回避
- encompassing 全方位，包括
- indispensable 必不可少的
- needle-in-a-haystack 大海捞针
